{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5112c65",
   "metadata": {},
   "source": [
    "# üöï NYC Taxi Streaming Demo - Databricks Free Edition (SEM DBFS)\n",
    "\n",
    "‚ú® **Compat√≠vel com Databricks Free Edition - Sem DBFS**\n",
    "\n",
    "Este notebook demonstra **Structured Streaming** usando o dataset p√∫blico **NYC Taxi** dispon√≠vel nativamente no Databricks.\n",
    "\n",
    "## üéØ Objetivos da Demonstra√ß√£o\n",
    "- Processar dados reais de t√°xis de NYC com streaming\n",
    "- Usar **maxFilesPerTrigger e maxBytesPerTrigger** para controlar velocidade de processamento\n",
    "- Demonstrar agrega√ß√µes em tempo real (viagens por regi√£o, receita por tipo de pagamento)\n",
    "- Salvar resultados **diretamente em Delta Tables** (Unity Catalog)\n",
    "- Visualizar m√©tricas batch por batch com foreachBatch\n",
    "\n",
    "## üìä Dataset: samples.nyctaxi.trips\n",
    "- **Fonte:** Unity Catalog do Databricks (j√° dispon√≠vel!)\n",
    "- **Registros:** Milh√µes de viagens de t√°xi em NYC\n",
    "- **Per√≠odo:** Dados hist√≥ricos de t√°xis amarelos e verdes\n",
    "- **Campos:** pickup/dropoff datetime, locations, distances, fares, payment types\n",
    "\n",
    "## ‚úÖ Vantagens desta abordagem\n",
    "- ‚ùå Sem Kafka externo (Free Edition tem rede restrita)\n",
    "- ‚ùå **Sem DBFS** (Public DBFS root est√° desabilitado)\n",
    "- ‚ùå Sem FileStore (tamb√©m desabilitado)\n",
    "- ‚úÖ Usa dados REAIS (n√£o sint√©ticos)\n",
    "- ‚úÖ 100% nativo do Databricks com Delta Tables\n",
    "- ‚úÖ Zero configura√ß√£o de rede ou filesystem externo\n",
    "- ‚úÖ Perfeito para demonstra√ß√µes educacionais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23ff284",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup e Configura√ß√£o (SEM DBFS)\n",
    "\n",
    "Vamos configurar o streaming **diretamente** da tabela Unity Catalog, salvando em Delta Tables gerenciadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56391d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import time\n",
    "\n",
    "# Configura√ß√µes do streaming - TUDO GERENCIADO, SEM DBFS\n",
    "TABLE_SOURCE = \"samples.nyctaxi.trips\"\n",
    "OUTPUT_TABLE = \"default.nyctaxi_streaming_results\"  # Tabela Delta gerenciada no Catalog\n",
    "\n",
    "print(\"üöï NYC TAXI STREAMING DEMO (SEM DBFS)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"üìä Fonte:      {TABLE_SOURCE} (Unity Catalog)\")\n",
    "print(f\"üíæ Destino:    {OUTPUT_TABLE} (Delta Table Gerenciada)\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n‚úÖ Abordagem:\")\n",
    "print(\"   ‚Ä¢ Ler diretamente de Unity Catalog com readStream\")\n",
    "print(\"   ‚Ä¢ Processar batches controlados por maxFilesPerTrigger e maxBytesPerTrigger\")\n",
    "print(\"   ‚Ä¢ Salvar em Delta Table gerenciada (sem DBFS)\")\n",
    "print(\"   ‚Ä¢ Visualizar m√©tricas com foreachBatch\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942ceec1",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Explorar Dados da Tabela NYC Taxi\n",
    "\n",
    "Vamos primeiro entender os dados dispon√≠veis na tabela Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0a5ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Explorando samples.nyctaxi.trips...\")\n",
    "\n",
    "# Ler amostra da tabela NYC Taxi\n",
    "nyctaxi_sample = spark.table(TABLE_SOURCE).limit(10)\n",
    "\n",
    "print(\"\\nüìã Schema dos dados:\")\n",
    "nyctaxi_sample.printSchema()\n",
    "\n",
    "print(\"\\nüîç Amostra dos primeiros registros:\")\n",
    "nyctaxi_sample.show(5, truncate=False)\n",
    "\n",
    "# Estat√≠sticas r√°pidas\n",
    "print(\"\\nüìà Estat√≠sticas r√°pidas (sample):\")\n",
    "nyctaxi_sample.select(\n",
    "    count(\"*\").alias(\"registros\"),\n",
    "    min(\"tpep_pickup_datetime\").alias(\"primeira_viagem\"),\n",
    "    max(\"tpep_pickup_datetime\").alias(\"ultima_viagem\"),\n",
    "    avg(\"trip_distance\").alias(\"distancia_media\"),\n",
    "    avg(\"total_amount\").alias(\"valor_medio\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db7baff",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Configurar Structured Streaming da Tabela Delta\n",
    "\n",
    "Vamos criar um streaming **direto da tabela** usando `maxFilesPerTrigger` e `maxBytesPerTrigger` para controlar a velocidade de processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53f5c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar streaming DataFrame diretamente da tabela Unity Catalog\n",
    "streaming_df = spark.readStream \\\n",
    "    .option(\"maxFilesPerTrigger\", 2) \\\n",
    "    .option(\"maxBytesPerTrigger\", \"5m\") \\\n",
    "    .table(TABLE_SOURCE)\n",
    "\n",
    "print(\"‚úÖ Streaming configurado!\")\n",
    "print(f\"‚öôÔ∏è  Fonte: {TABLE_SOURCE}\")\n",
    "print(f\"‚öôÔ∏è  maxFilesPerTrigger: 2 (processa at√© 2 arquivos Delta por batch)\")\n",
    "print(f\"‚öôÔ∏è  maxBytesPerTrigger: 5m (m√°ximo 5MB por batch)\")\n",
    "print(f\"üìä √â streaming? {streaming_df.isStreaming}\")\n",
    "print(\"\\nüìã Schema:\")\n",
    "streaming_df.printSchema()\n",
    "\n",
    "print(\"\\nüí° Nota: O streaming ler√° incrementalmente os arquivos da tabela Delta,\")\n",
    "print(\"   processando alguns arquivos por batch para demonstra√ß√£o visual.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759164de",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Enriquecer e Agregar Dados\n",
    "\n",
    "Adicionamos colunas de an√°lise e criamos agrega√ß√µes por regi√£o e tipo de pagamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb78e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enriquecer dados\n",
    "enriched_df = streaming_df \\\n",
    "    .withColumn(\"processing_time\", current_timestamp()) \\\n",
    "    .withColumn(\"pickup_date\", to_date(col(\"tpep_pickup_datetime\"))) \\\n",
    "    .withColumn(\"pickup_hour\", hour(col(\"tpep_pickup_datetime\"))) \\\n",
    "    .withColumn(\"trip_duration_minutes\", \n",
    "                (unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp(\"tpep_pickup_datetime\")) / 60) \\\n",
    "    .withColumn(\"payment_type_desc\", \n",
    "                when(col(\"payment_type\") == 1, \"Credit Card\")\n",
    "                .when(col(\"payment_type\") == 2, \"Cash\")\n",
    "                .when(col(\"payment_type\") == 3, \"No Charge\")\n",
    "                .when(col(\"payment_type\") == 4, \"Dispute\")\n",
    "                .otherwise(\"Unknown\"))\n",
    "\n",
    "# Agrega√ß√µes por localiza√ß√£o de pickup e tipo de pagamento\n",
    "aggregated_df = enriched_df \\\n",
    "    .groupBy(\"pickup_location_id\", \"payment_type_desc\", \"pickup_date\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"total_trips\"),\n",
    "        sum(\"trip_distance\").alias(\"total_distance\"),\n",
    "        sum(\"total_amount\").alias(\"total_revenue\"),\n",
    "        avg(\"total_amount\").alias(\"avg_fare\"),\n",
    "        avg(\"trip_distance\").alias(\"avg_distance\"),\n",
    "        avg(\"trip_duration_minutes\").alias(\"avg_duration_min\"),\n",
    "        min(\"tpep_pickup_datetime\").alias(\"first_trip\"),\n",
    "        max(\"tpep_pickup_datetime\").alias(\"last_trip\")\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Pipeline de agrega√ß√£o criado!\")\n",
    "print(\"\\nüìä M√©tricas calculadas:\")\n",
    "print(\"  ‚Ä¢ Total de viagens\")\n",
    "print(\"  ‚Ä¢ Dist√¢ncia total percorrida\")\n",
    "print(\"  ‚Ä¢ Receita total\")\n",
    "print(\"  ‚Ä¢ Ticket m√©dio (fare)\")\n",
    "print(\"  ‚Ä¢ Dist√¢ncia m√©dia\")\n",
    "print(\"  ‚Ä¢ Dura√ß√£o m√©dia (minutos)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7705062",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ foreachBatch - Processar e Visualizar Cada Batch\n",
    "\n",
    "Usamos `foreachBatch` para ver o processamento **batch por batch** em tempo real!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc1bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estat√≠sticas acumuladas\n",
    "batch_stats = {\n",
    "    'count': 0,\n",
    "    'total_trips': 0,\n",
    "    'total_revenue': 0,\n",
    "    'total_distance': 0\n",
    "}\n",
    "\n",
    "def process_batch(batch_df, batch_id):\n",
    "    \"\"\"Processa cada batch do streaming\"\"\"\n",
    "    batch_stats['count'] += 1\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(f\"üì¶ BATCH #{batch_stats['count']} | Batch ID: {batch_id}\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    if batch_df.count() == 0:\n",
    "        print(\"‚ö†Ô∏è  Batch vazio - pulando\")\n",
    "        return\n",
    "    \n",
    "    # Estat√≠sticas do batch\n",
    "    stats = batch_df.agg(\n",
    "        sum(\"total_trips\").alias(\"trips\"),\n",
    "        sum(\"total_revenue\").alias(\"revenue\"),\n",
    "        sum(\"total_distance\").alias(\"distance\")\n",
    "    ).collect()[0]\n",
    "    \n",
    "    batch_stats['total_trips'] += stats.trips if stats.trips else 0\n",
    "    batch_stats['total_revenue'] += stats.revenue if stats.revenue else 0\n",
    "    batch_stats['total_distance'] += stats.distance if stats.distance else 0\n",
    "    \n",
    "    print(f\"\\nüìä ESTAT√çSTICAS DO BATCH:\")\n",
    "    print(f\"   üöï Viagens: {stats.trips:,}\")\n",
    "    print(f\"   üí∞ Receita: ${stats.revenue:,.2f}\")\n",
    "    print(f\"   üìè Dist√¢ncia: {stats.distance:,.2f} milhas\")\n",
    "    \n",
    "    # Top 5 localiza√ß√µes por receita\n",
    "    print(f\"\\nüèÜ TOP 5 LOCALIZA√á√ïES (Receita):\")\n",
    "    top_locations = batch_df.orderBy(col(\"total_revenue\").desc()).limit(5)\n",
    "    top_locations.select(\n",
    "        \"pickup_location_id\",\n",
    "        \"total_trips\",\n",
    "        \"total_revenue\",\n",
    "        \"avg_fare\"\n",
    "    ).show(truncate=False)\n",
    "    \n",
    "    # Distribui√ß√£o por tipo de pagamento\n",
    "    print(f\"üí≥ DISTRIBUI√á√ÉO POR TIPO DE PAGAMENTO:\")\n",
    "    payment_dist = batch_df.groupBy(\"payment_type_desc\") \\\n",
    "        .agg(\n",
    "            sum(\"total_trips\").alias(\"trips\"),\n",
    "            sum(\"total_revenue\").alias(\"revenue\")\n",
    "        ) \\\n",
    "        .orderBy(col(\"revenue\").desc())\n",
    "    payment_dist.show(truncate=False)\n",
    "    \n",
    "    # Totais acumulados\n",
    "    print(f\"\\nüìà TOTAIS ACUMULADOS:\")\n",
    "    print(f\"   üì¶ Batches processados: {batch_stats['count']}\")\n",
    "    print(f\"   üöï Viagens: {batch_stats['total_trips']:,}\")\n",
    "    print(f\"   üí∞ Receita: ${batch_stats['total_revenue']:,.2f}\")\n",
    "    print(f\"   üìè Dist√¢ncia: {batch_stats['total_distance']:,.2f} milhas\")\n",
    "    if batch_stats['total_trips'] > 0:\n",
    "        print(f\"   üéØ Receita M√©dia/Viagem: ${batch_stats['total_revenue']/batch_stats['total_trips']:,.2f}\")\n",
    "\n",
    "print(\"üîß Fun√ß√£o de processamento definida!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbae07c",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ EXECUTAR Streaming com foreachBatch\n",
    "\n",
    "**Execute esta c√©lula e observe o processamento batch por batch!**\n",
    "\n",
    "O streaming ir√°:\n",
    "1. Processar dados incrementalmente da tabela Delta\n",
    "2. Mostrar m√©tricas de cada batch\n",
    "3. Acumular estat√≠sticas totais\n",
    "4. Executar por 60 segundos (ou at√© processar todos os dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07621dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Iniciando streaming...\\n\")\n",
    "\n",
    "# Iniciar streaming com foreachBatch\n",
    "query = aggregated_df.writeStream \\\n",
    "    .foreachBatch(process_batch) \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .trigger(processingTime=\"5 seconds\") \\\n",
    "    .start()\n",
    "\n",
    "print(\"‚úÖ Streaming iniciado!\")\n",
    "print(\"‚è±Ô∏è  Executar√° por 60 segundos...\")\n",
    "print(\"\\nüëÄ Observe as m√©tricas sendo atualizadas abaixo:\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c918e1",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Aguardar e Parar o Streaming\n",
    "\n",
    "Deixe o streaming executar por 60 segundos para ver v√°rios batches, depois pare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2a05ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aguardar 60 segundos\n",
    "print(\"‚è≥ Aguardando 60 segundos...\")\n",
    "time.sleep(60)\n",
    "\n",
    "# Parar o streaming\n",
    "query.stop()\n",
    "print(\"\\nüõë Streaming parado!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"üìä RESUMO FINAL\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"üì¶ Total de batches processados: {batch_stats['count']}\")\n",
    "print(f\"üöï Total de viagens: {batch_stats['total_trips']:,}\")\n",
    "print(f\"üí∞ Receita total: ${batch_stats['total_revenue']:,.2f}\")\n",
    "print(f\"üìè Dist√¢ncia total: {batch_stats['total_distance']:,.2f} milhas\")\n",
    "if batch_stats['total_trips'] > 0:\n",
    "    print(f\"üéØ Receita m√©dia por viagem: ${batch_stats['total_revenue']/batch_stats['total_trips']:,.2f}\")\n",
    "    print(f\"üìç Dist√¢ncia m√©dia por viagem: {batch_stats['total_distance']/batch_stats['total_trips']:,.2f} milhas\")\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc08760",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ ALTERNATIVA: Salvar em Delta Table Gerenciada\n",
    "\n",
    "Em vez de usar `foreachBatch`, podemos salvar diretamente em uma **Delta Table gerenciada** no Catalog.\n",
    "\n",
    "**Vantagens:**\n",
    "- Dados persistidos automaticamente\n",
    "- Pode consultar com SQL\n",
    "- Suporta ACID transactions\n",
    "- Gerenciado pelo Unity Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b774cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üíæ Salvando resultados em Delta Table: {OUTPUT_TABLE}\")\n",
    "\n",
    "# Limpar tabela anterior se existir\n",
    "try:\n",
    "    spark.sql(f\"DROP TABLE IF EXISTS {OUTPUT_TABLE}\")\n",
    "    print(f\"üßπ Tabela anterior removida\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Iniciar streaming salvando em Delta Table\n",
    "query_delta = aggregated_df.writeStream \\\n",
    "    .format(\"delta\") \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .option(\"checkpointLocation\", f\"/tmp/checkpoint_{int(time.time())}\") \\\n",
    "    .trigger(processingTime=\"10 seconds\") \\\n",
    "    .toTable(OUTPUT_TABLE)\n",
    "\n",
    "print(f\"‚úÖ Streaming para Delta Table iniciado!\")\n",
    "print(f\"üìä Tabela: {OUTPUT_TABLE}\")\n",
    "print(f\"‚è±Ô∏è  Trigger: 10 segundos\")\n",
    "print(f\"\\nüí° A tabela ser√° atualizada automaticamente a cada 10 segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ce0fcd",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Aguardar Processamento da Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80886deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aguardar 60 segundos para processar dados\n",
    "print(\"‚è≥ Aguardando 60 segundos para processar dados...\")\n",
    "time.sleep(60)\n",
    "\n",
    "# Parar o streaming\n",
    "query_delta.stop()\n",
    "print(\"üõë Streaming para Delta Table parado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029cf0aa",
   "metadata": {},
   "source": [
    "## üîü Consultar Resultados da Delta Table\n",
    "\n",
    "Agora podemos consultar os resultados salvos na Delta Table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eaef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üìä Consultando resultados de {OUTPUT_TABLE}...\\n\")\n",
    "\n",
    "# Ler a tabela\n",
    "results_df = spark.table(OUTPUT_TABLE)\n",
    "\n",
    "print(f\"‚úÖ Total de registros salvos: {results_df.count():,}\\n\")\n",
    "\n",
    "# Top 10 localiza√ß√µes por receita\n",
    "print(\"üèÜ TOP 10 LOCALIZA√á√ïES (Receita Total):\")\n",
    "results_df.orderBy(col(\"total_revenue\").desc()).limit(10).show(truncate=False)\n",
    "\n",
    "# Estat√≠sticas gerais\n",
    "print(\"\\nüìà ESTAT√çSTICAS GERAIS:\")\n",
    "totals = results_df.agg(\n",
    "    sum(\"total_trips\").alias(\"total_viagens\"),\n",
    "    sum(\"total_revenue\").alias(\"receita_total\"),\n",
    "    sum(\"total_distance\").alias(\"distancia_total\"),\n",
    "    avg(\"avg_fare\").alias(\"ticket_medio\"),\n",
    "    avg(\"avg_distance\").alias(\"distancia_media_viagem\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"  üöï Total de viagens: {totals.total_viagens:,}\")\n",
    "print(f\"  üí∞ Receita total: ${totals.receita_total:,.2f}\")\n",
    "print(f\"  üìè Dist√¢ncia total: {totals.distancia_total:,.2f} milhas\")\n",
    "print(f\"  üéØ Ticket m√©dio: ${totals.ticket_medio:,.2f}\")\n",
    "print(f\"  üìç Dist√¢ncia m√©dia por viagem: {totals.distancia_media_viagem:,.2f} milhas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebdfbef",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Consultar com SQL\n",
    "\n",
    "Podemos usar SQL diretamente na tabela Delta!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421c5aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de consulta SQL\n",
    "spark.sql(f\"\"\"\n",
    "SELECT \n",
    "    payment_type_desc,\n",
    "    SUM(total_trips) as viagens,\n",
    "    SUM(total_revenue) as receita,\n",
    "    AVG(avg_fare) as ticket_medio\n",
    "FROM {OUTPUT_TABLE}\n",
    "GROUP BY payment_type_desc\n",
    "ORDER BY receita DESC\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0766e7f2",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Cleanup (Opcional)\n",
    "\n",
    "Remova a tabela de testes se desejar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6673fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomentar para executar cleanup\n",
    "# spark.sql(f\"DROP TABLE IF EXISTS {OUTPUT_TABLE}\")\n",
    "# print(f\"üßπ Tabela {OUTPUT_TABLE} removida\")\n",
    "\n",
    "print(\"‚ÑπÔ∏è  Cleanup desabilitado. Descomente o c√≥digo acima para remover a tabela.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0cf44d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Conceitos Demonstrados\n",
    "\n",
    "### Structured Streaming\n",
    "- **readStream**: L√™ dados de forma incremental de tabelas Delta\n",
    "- **maxFilesPerTrigger**: Controla quantos arquivos processar por batch\n",
    "- **maxBytesPerTrigger**: Controla volume de dados por batch\n",
    "- **writeStream**: Salva resultados do streaming\n",
    "- **foreachBatch**: Fun√ß√£o customizada para processar cada batch\n",
    "- **outputMode=complete**: Retorna resultados completos das agrega√ß√µes\n",
    "\n",
    "### Delta Lake\n",
    "- **Delta Tables gerenciadas**: Tabelas no Unity Catalog\n",
    "- **ACID transactions**: Garantia de consist√™ncia\n",
    "- **Time travel**: Hist√≥rico de vers√µes (n√£o explorado aqui)\n",
    "- **Schema enforcement**: Valida√ß√£o autom√°tica de schema\n",
    "\n",
    "### Unity Catalog\n",
    "- **samples.nyctaxi.trips**: Dataset p√∫blico nativo\n",
    "- **default schema**: Schema padr√£o para tabelas\n",
    "- **Managed tables**: Metadados e dados gerenciados\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Checklist de Execu√ß√£o\n",
    "\n",
    "1. ‚úÖ Configurar vari√°veis (TABLE_SOURCE, OUTPUT_TABLE)\n",
    "2. ‚úÖ Explorar dados da tabela NYC Taxi\n",
    "3. ‚úÖ Configurar streaming com maxFilesPerTrigger\n",
    "4. ‚úÖ Criar pipeline de agrega√ß√µes\n",
    "5. ‚úÖ Executar com foreachBatch (Op√ß√£o 1)\n",
    "   - Ver m√©tricas batch por batch\n",
    "   - Aguardar 60 segundos\n",
    "   - Parar streaming\n",
    "6. ‚úÖ OU Salvar em Delta Table (Op√ß√£o 2)\n",
    "   - Iniciar streaming para Delta\n",
    "   - Aguardar 60 segundos\n",
    "   - Parar streaming\n",
    "   - Consultar resultados\n",
    "7. ‚úÖ Consultar com SQL\n",
    "8. ‚úÖ Cleanup (opcional)\n",
    "\n",
    "---\n",
    "\n",
    "## üéì Para Professores\n",
    "\n",
    "Este notebook √© ideal para demonstrar:\n",
    "\n",
    "1. **Processamento Incremental**: Como o Spark processa dados em batches\n",
    "2. **Agrega√ß√µes em Streaming**: GroupBy com fun√ß√µes de agrega√ß√£o\n",
    "3. **Delta Lake**: Vantagens de usar Delta vs Parquet\n",
    "4. **Unity Catalog**: Governan√ßa e organiza√ß√£o de dados\n",
    "5. **Controle de Fluxo**: maxFilesPerTrigger e maxBytesPerTrigger\n",
    "6. **Visualiza√ß√£o de M√©tricas**: foreachBatch para inspe√ß√£o\n",
    "\n",
    "**Sem necessidade de:**\n",
    "- Kafka ou sistemas externos\n",
    "- DBFS ou FileStore\n",
    "- Configura√ß√£o de rede\n",
    "- Dados sint√©ticos\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Recursos\n",
    "\n",
    "- [Databricks Structured Streaming](https://docs.databricks.com/structured-streaming/index.html)\n",
    "- [Delta Lake](https://docs.databricks.com/delta/index.html)\n",
    "- [Unity Catalog](https://docs.databricks.com/data-governance/unity-catalog/index.html)\n",
    "- [NYC Taxi Dataset](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
